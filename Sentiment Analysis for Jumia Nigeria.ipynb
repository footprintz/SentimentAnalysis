{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT OF VARIOUS LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn as skn  \n",
    "import numpy as np \n",
    "import scipy \n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import model_selection \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing Data \n",
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords as sw \n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize \n",
    "from nltk import sent_tokenize \n",
    "from nltk import WordNetLemmatizer \n",
    "from nltk import pos_tag \n",
    "from nltk import RegexpTokenizer\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "# vectorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING OF THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good buy</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's good and affordable have ordered over 15 ...</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice scent. Doesn't stick when used. Dries alm...</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Jumia, Quality is good,Thank you Jumia.</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good one</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments      rating\n",
       "0                                           Good buy  5 out of 5\n",
       "1  It's good and affordable have ordered over 15 ...  4 out of 5\n",
       "2  Nice scent. Doesn't stick when used. Dries alm...  5 out of 5\n",
       "3      Hello Jumia, Quality is good,Thank you Jumia.  5 out of 5\n",
       "4                                           Good one  5 out of 5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GETTING THE STORED DATASET \n",
    "text_data = pd.read_csv('Reviews.csv') \n",
    "text_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning/preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good buy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's good and affordable have ordered over 15 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice scent. Doesn't stick when used. Dries alm...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Jumia, Quality is good,Thank you Jumia.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good one</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It is good to the touch. No residues left over...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Its good smells nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Love the fragrance</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100%%\\nWorking fine</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nice product</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments rating\n",
       "0                                           Good buy      5\n",
       "1  It's good and affordable have ordered over 15 ...      4\n",
       "2  Nice scent. Doesn't stick when used. Dries alm...      5\n",
       "3      Hello Jumia, Quality is good,Thank you Jumia.      5\n",
       "4                                           Good one      5\n",
       "5  It is good to the touch. No residues left over...      5\n",
       "6                               Its good smells nice      4\n",
       "7                                 Love the fragrance      5\n",
       "8                                100%%\\nWorking fine      5\n",
       "9                                       Nice product      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing 'out of 5 ' from the rating to leave the values '4, 5, 3, 2, 1'\n",
    "text_data['rating'] = text_data['rating'].str.replace('out of 5', ' ').str.strip() \n",
    "text_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's good and affordable have ordered over 15 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice scent. Doesn't stick when used. Dries alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Jumia, Quality is good,Thank you Jumia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It is good to the touch. No residues left over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Its good smells nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Love the fragrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100%%\\nWorking fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nice product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments\n",
       "0                                           Good buy\n",
       "1  It's good and affordable have ordered over 15 ...\n",
       "2  Nice scent. Doesn't stick when used. Dries alm...\n",
       "3      Hello Jumia, Quality is good,Thank you Jumia.\n",
       "4                                           Good one\n",
       "5  It is good to the touch. No residues left over...\n",
       "6                               Its good smells nice\n",
       "7                                 Love the fragrance\n",
       "8                                100%%\\nWorking fine\n",
       "9                                       Nice product"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the comments and in another variable ; comments \n",
    "comments = text_data[['comments']]\n",
    "comments  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating\n",
       "0      5\n",
       "1      4\n",
       "2      5\n",
       "3      5\n",
       "4      5\n",
       "5      5\n",
       "6      4\n",
       "7      5\n",
       "8      5\n",
       "9      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the ratings in another variable ; rating \n",
    "rating = text_data[['rating']] \n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Good buy'],\n",
       " [\"It's good and affordable have ordered over 15 bottles so far\"],\n",
       " [\"Nice scent. Doesn't stick when used. Dries almost immediately.\"],\n",
       " ['Hello Jumia, Quality is good,Thank you Jumia.'],\n",
       " ['Good one'],\n",
       " ['It is good to the touch. No residues left over. Quality stuff.'],\n",
       " ['Its good smells nice'],\n",
       " ['Love the fragrance'],\n",
       " ['100%%\\nWorking fine'],\n",
       " ['Nice product']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the dataframe into a list \n",
    "comment_list = comments.values.tolist() \n",
    "comment_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning or preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/meri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#convert the list into string \n",
    "nltk.download('stopwords')\n",
    "text_data = str(comment_list)\n",
    "tokenizer = RegexpTokenizer(r'\\w+') \n",
    "en_stopwords = set(sw.words('english')) \n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_text = [] \n",
    "def to_lower_case(data): \n",
    "    for words in text_data: \n",
    "        lower_text.append(str.lower(words))\n",
    "\n",
    "\n",
    "to_lower_case(text_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization \n",
    "clean_text1 = text_data.lower()\n",
    "clean_text_2 = clean_text1.split() \n",
    "#turn the text into lower case \n",
    "clean_text1 = text_data.lower()\n",
    "#word tokenization using regular expression \n",
    "tokens_1 = re.findall(\"[\\w']+\",clean_text1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove symbols \n",
    "clean_text_2 = [] \n",
    "\n",
    "\n",
    "for words in tokens_1:\n",
    "    clean = []\n",
    "    #for w in words: \n",
    "    res = re.sub(r'[^A-Za-z0-9]+', \"\", words)\n",
    "    if res != \"\":\n",
    "        clean.append(res)\n",
    "    clean_text_2.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop word removal \n",
    "clean_text_3 = [] \n",
    "\n",
    "for words in clean_text_2:\n",
    "    w = []\n",
    "    for word in words: \n",
    "        if word not in sw.words('english'):\n",
    "            w.append(word)\n",
    "            clean_text_3.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sw.words('english')\n",
    "stop_words = set(sw.words('english'))\n",
    "filtered_word = [] \n",
    "for w in clean_text_2: \n",
    "    if w not in stop_words: \n",
    "        filtered_word.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming: this is used to remove the prefix/suffix of a word or make a word it root form  \n",
    "stem_words = []\n",
    "port = PorterStemmer()\n",
    "for w in filtered_word: \n",
    "    rootWord = ps.stem(w)\n",
    "    stem_words.append(rootWord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/meri/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "lemma_words = []\n",
    "wordnet_lemmatizer = WordNetLemmatizer() \n",
    "for w in filtered_word: \n",
    "    word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
    "    word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
    "    word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
    "    lemma_words.append(word3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBaiyes_Sentimental(word):\n",
    "    blob = TextBlob(word, analyzer=NaiveBayesAnalyzer())\n",
    "    NaiveBayes_SentimentScore=blob.sentiment.classification\n",
    "    return NaiveBayes_SentimentScore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['good', 'buy', 'good', 'affordable', 'order', '15', 'bottle', 'far', 'nice', 'scent', 'doesnt', 'stick', 'use', 'dry', 'almost', 'immediately', 'hello', 'jumia', 'quality', 'good', 'thank', 'jumia', '', 'good', 'one', 'good', 'touch', 'residue', 'leave', 'quality', 'stuff', '', 'good', 'smell', 'nice', 'love', 'fragrance', '100', 'nworking', 'fine', 'nice', 'product']\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_data = str(lemma_words) \n",
    "string_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/meri/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/meri/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the string of data where 'pos' = positive(1.0), 'neg'(0.0) = negative, 'neu' = neural \n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "NaiveBaiyes_Sentimental(string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(word): \n",
    "    def getSubjectivity(text): \n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "    \n",
    "    # create a function to get the polarity \n",
    "    def getPolarity(text): \n",
    "        return TextBlob(text).sentiment.polarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis(string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data \n",
    "y_train = [1,1,1,1,1,0,0,0,0,0] #1 = Positive, #0 = Negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many times a word appear in the array it is also called bagofwords model \n",
    "cv = CountVectorizer(ngram_range=(1,1))\n",
    "x_vec = cv.fit_transform(lemma_words).toarray()#convert the text into array \n",
    "\n",
    "x_vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_vect = cv.transform(lemma_words).toarray()\n",
    "\n",
    "xt_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Multinomial Naive Bayes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_vec, lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/meri/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4404}\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "senti = SentimentIntensityAnalyzer()\n",
    "print(senti.polarity_scores('good'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
